---
title: "GAN 정리"
use_math: true
classes: wide
layout: single
---
  
**본 자료는 다음을 정리했습니다.**  
- [GAN by Ian Goodfellow](https://arxiv.org/abs/1406.2661) 
- [lil'log blog post](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html) 
- [Wasserstein GAN](https://arxiv.org/abs/1701.07875) 
- [GAN tutorial](https://arxiv.org/abs/1701.00160) 
- [Training tricks](https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/)
- [Mathematics in Wasserstein GAN](https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i)
  
  
지난 5년 간 GAN은 양적, 질적으로 폭발적인 성장을 이뤄냈다. 여기서는 original paper에서 제안한 GAN의 Information-theoretic perspective와, 
Neural Net 적용 과정에서의 practical limitations, 이를 해소하기 위한 WGAN과 WGAN-GP, 마지막으로 GAN의 다양한 후속 연구 및 도메인 적용에 대해 
알아본다. 
  
  
**0. Vanila GAN and Information-theoretic perspective of GAN**  
GAN은 discriminator와 generator의 dual architecture로 이뤄져 있다. 
Discriminator는 real images와 fake images을 구분하는 neural network으로 critic이라고도 불린다. 
반면 Generator는 fake image를 잘 만들어 discriminator를 속여야 한다. 
GAN을 나름대로 해석하는 시각은 굉장히 다양한데, Game theory의 Nash equilibrium으로 이를 해석하는 경우가 있고, 
Discriminator 자체를 Generator의 loss function으로 받아 들이는 경우가 있다. 
개인적으로는 이를 E-M 알고리즘에 근사시킬 수 있다고 생각하는데, latent variable z를 label {0, 1}로 두고  
discriminator(D)가 parameter $$\phi$$를 max likelihood $$p(x,z \mid \phi)$$ 방향으로 업데이트하면, 
generator(G)가 해당 $$p(z \mid \phi)$$를 따라가는 방향으로 generated probabilistic distribution Q를 업데이트하는 방식이다. 
  
어쨌든 결론은 G와 D가 서로 경쟁하는 구도이며 G는 D를 속이고, D는 G에게 속지 않아야 하는 zero-sum 구도이다. 
이를 loss function으로 나타내면 다음과 같다. 
  
$$L_D = argmax_{\phi} log(D(x \mid \phi)) + log(1-D(G(z) \mid \phi))$$  
$$L_G = argmin_{\theta} log(1-D(G(z \mid \theta)))$$  
D는 given images를 판정함으로써 본인의 gain을 최대화하려 하고, G는 판정에 의한 본인의 loss를 최소화하려는 Min-Max 게임이다.  
  
![그림5](https://user-images.githubusercontent.com/46081019/59493870-e51c0b80-8ec6-11e9-9dd8-1537e7e7575f.PNG)  
그림에서 파란 점선은 discriminative function, 검은 점선은 Real data distribution (Samples represented with dots), 
초록 실선은 generative function이다. Random noise z에서 x를 generate하는 mapping이 $$x=G(z)$$이다. 
Generative function이 아직 converge되지 않은 (b)에서 discriminative function은 
쉽게 초록색과 검은색을 구별해 낸다. 이때 Discriminator에서 받은 feedback gradient를 바탕으로, 
(c)에서 G(z)는 real data distribution에 가까워진다. 
최종적으로 학습이 평형을 이루게 되면 real data distribution과 fake data distribution은 합치를 이루고 $$D(x)=\frac{1}{2}$$에 수렴한다. 
  
GAN의 original paper에서 나와있듯이, vanila GAN은 optimal함을 가정했을 때 JS divergence를 minimize한다. 
이 때 필요한 가정은 몇 가지가 있는데, 
- Discriminator의 bayes optimal이 유일하게 존재한다. 
- Discriminator가 위의 optimal state일 때 Generator를 학습시킨다. 
또한 GAN은 이 JS divergence를 minimize하여 unique global optimum에 도달할 수 있는데, 이 때 필요한 가정은 
- G와 D가 enough capacity(in terms of probabilistic distribution)을 가져야 한다.
- Discriminator가 optimal state에 도달할 수 있다.
  
다음 절에서 위의 가정을 Neural Network에 적용시 나타나는 문제점을 다루고자 한다. 우선 JS-div의 유도는 다음과 같다.  
**1. Global Optimality of $$p_g=p_{data}$$**    
![image](https://user-images.githubusercontent.com/46081019/59495311-0cc0a300-8eca-11e9-97bd-58237add1f0b.png)  
앞서 기술한 discriminator의 loss를 x의 연속계에 대해 적분 형태로 표현하였다. 
이 때 $$p_z(z)$$에 의해 대응되는 generated $$x$$의 확률을 $$p_g(x)$$라고 하면, real or fake x에 대해서 동일한 형태로 
수식을 합칠 수 있다. 이후 과정은 자명하다. 이때 Discriminator는 $$Supp(p_{data}) \cup Supp(p_g)$$ 외 영역에서는 정의될 필요가 없다고 하는데, 
$$Supp$$는 support를 얘기하는 것 같고, 
쉽게 말하면 $$p_{data}$$와 $$p_{g}$$ 관점에서 보았을 때 전혀 가능성이 없는 데이터 $$x$$에 대해서는 고려할 필요가 없다는 뜻이다. 
X-ray 이미지를 생성하는데 강아지 이미지에 대해 loss를 일일히 계산하고 있을 필요는 없다. 
단, 두 확률분포의 support가 완벽히 분리되어 있는 경우에는 문제가 생길 수 있는데 이는 다음 절에서 더 다루고자 한다.  

**2. 

**1. Practical and Theoretical Limitation of training GAN**  

**2. Theoretical: WGAN and WGAN-GP**  

**3. Practical examples: Tricks and Training**  

**4. Other GANs**  
