---
title: "GAN 정리"
use_math: true
classes: wide
layout: single
---
  
**본 자료는 다음을 정리했습니다.**  
- [GAN by Ian Goodfellow](https://arxiv.org/abs/1406.2661) 
- [lil'log blog post](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html) 
- [Wasserstein GAN](https://arxiv.org/abs/1701.07875) 
- [GAN tutorial](https://arxiv.org/abs/1701.00160) 
- [Training tricks](https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/)
- [Mathematics in Wasserstein GAN](https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i)
  
  
지난 5년 간 GAN은 양적, 질적으로 폭발적인 성장을 이뤄냈다. 여기서는 original paper에서 제안한 GAN의 Information-theoretic perspective와, 
Neural Net 적용 과정에서의 practical limitations, 이를 해소하기 위한 WGAN과 WGAN-GP, 마지막으로 GAN의 다양한 후속 연구 및 도메인 적용에 대해 
알아본다. 
  
  
**0. Vanila GAN and Information-theoretic perspective of GAN**  
GAN은 discriminator와 generator의 dual architecture로 이뤄져 있다. 
Discriminator는 real images와 fake images을 구분하는 neural network으로 critic이라고도 불린다. 
반면 Generator는 fake image를 잘 만들어 discriminator를 속여야 한다. 
GAN을 나름대로 해석하는 시각은 굉장히 다양한데, Game theory의 Nash equilibrium으로 이를 해석하는 경우가 있고, 
Discriminator 자체를 Generator의 loss function으로 받아 들이는 경우가 있다. 
개인적으로는 이를 E-M 알고리즘에 근사시킬 수 있다고 생각하는데, latent variable z를 label {0, 1}로 두고  
discriminator(D)가 parameter $$\phi$$를 max likelihood $$p(x,z \mid \phi)$$ 방향으로 업데이트하면, 
generator(G)가 해당 $$p(z \mid \phi)$$를 따라가는 방향으로 generated probabilistic distribution Q를 업데이트하는 방식이다. 
  
어쨌든 결론은 G와 D가 서로 경쟁하는 구도이며 G는 D를 속이고, D는 G에게 속지 않아야 하는 zero-sum 구도이다. 
이를 loss function으로 나타내면 다음과 같다. 
  
$$L_D = argmax_{\phi} log(D(x \mid \phi)) + log(1-D(G(z) \mid \phi))$$  
$$L_G = argmin_{\theta} log(1-D(G(z \mid \theta)))$$  
D는 given images를 판정함으로써 본인의 gain을 최대화하려 하고, G는 판정에 의한 본인의 loss를 최소화하려는 Min-Max 게임이다.  
  
![그림5](https://user-images.githubusercontent.com/46081019/59493870-e51c0b80-8ec6-11e9-9dd8-1537e7e7575f.PNG)  
그림에서 파란 점선은 discriminative function, 검은 점선은 Real data distribution (Samples represented with dots), 
초록 실선은 generative function이다. Random noise z에서 x를 generate하는 mapping이 $$x=G(z)$$이다. 
Generative function이 아직 converge되지 않은 (b)에서 discriminative function은 
쉽게 초록색과 검은색을 구별해 낸다. 이때 Discriminator에서 받은 feedback gradient를 바탕으로, 
(c)에서 G(z)는 real data distribution에 가까워진다. 
최종적으로 학습이 평형을 이루게 되면 real data distribution과 fake data distribution은 합치를 이루고 $$D(x)=\frac{1}{2}$$에 수렴한다. 
  
GAN의 original paper에서 나와있듯이, vanila GAN은 optimal함을 가정했을 때 JS divergence를 minimize한다. 
이 때 필요한 가정은 몇 가지가 있는데, 
- Discriminator의 bayes optimal이 유일하게 존재한다. 
- Discriminator가 위의 optimal state일 때 Generator를 학습시킨다. 
  
또한 GAN은 이 JS divergence를 minimize하여 unique global optimum에 도달할 수 있는데, 이 때 필요한 가정은 
- G와 D가 enough capacity(in terms of probabilistic distribution)을 가져야 한다.
- Discriminator가 optimal state에 도달할 수 있다.
  
다음 절에서 위의 가정을 Neural Network에 적용시 나타나는 문제점을 다루고자 한다. 우선 JS-div의 유도는 다음과 같다.  
**0.1. Global Optimality of $$p_g=p_{data}$$**    
![image](https://user-images.githubusercontent.com/46081019/59495311-0cc0a300-8eca-11e9-97bd-58237add1f0b.png)  
앞서 기술한 discriminator의 loss를 x의 연속계에 대해 적분 형태로 표현하였다. 
이 때 $$p_z(z)$$에 의해 대응되는 generated $$x$$의 확률을 $$p_g(x)$$라고 하면, real or fake x에 대해서 동일한 형태로 
수식을 합칠 수 있다. 이후 과정은 자명하다. 이때 Discriminator는 $$Supp(p_{data}) \cup Supp(p_g)$$ 외 영역에서는 정의될 필요가 없다고 하는데, 
$$Supp$$는 support를 얘기하는 것 같고, 
쉽게 말하면 $$p_{data}$$와 $$p_{g}$$ 관점에서 보았을 때 전혀 가능성이 없는 데이터 $$x$$에 대해서는 고려할 필요가 없다는 뜻이다. 
X-ray 이미지를 생성하는데 강아지 이미지에 대해 loss를 일일히 계산하고 있을 필요는 없다. 
단, 두 확률분포의 support가 완벽히 분리되어 있는 경우에는 문제가 생길 수 있는데 이는 다음 절에서 더 다루고자 한다.  
  
이러한 optimal bayes discriminator의 가정 아래 loss function은 다음과 같이 재정의된다. 
![image](https://user-images.githubusercontent.com/46081019/59501115-d0933f80-8ed5-11e9-988f-1eaf19d41646.png)  
이때 $$\begin{align} E_{p_d}[log \frac{p_d(x)}{p_d(x)+p_g(x)}] + E_{p_g}[log \frac{p_g(x)}{p_d(x)+p_g(x)}] 
\&=KL(p_d || p_d + p_g) + KL(p_g || p_d + p_g) 
\&=KL(p_d || \frac{p_d + p_g}{2}) + KL(p_g || \frac{p_d + p_g}{2}) - log(4) 
\&=2JS(p_d || p_g) - log(4)\end{align}$$  
  
이때 JS-divergence는 non-negative한 metric이기 때문에 주어진 loss가 가장 낮은 경우는 -log(4)이며 이때 $$p_d = p_g$$이다. 
Ian Goodfellow는 GAN 연구를 친구와의 대화 도중 직관적으로 떠오른 아이디어에서 시작하셨다는데, 
이렇게 그 직관이 이론적으로 엄밀하게 뒷받침되고 또 그걸 논리적으로 보여줄 수 있다는 점이 대단한 것 같다. 
  
**0.2. Comparison to VAE w.r.t specialty of GAN objective function**  
어쨌든 일반적으로 MLE에 기반한 여러 neural network 혹은 VAE가 KL divergence를 Minimize하는 반면에 GAN은 JS divergence를 minimize하는데, 이 차이가 왜 GAN이 기존의 여러 generative model 대비 훨씬 좋은 resolution을 보여주는지를 설명한다. 
![image](https://user-images.githubusercontent.com/46081019/59503260-dd666200-8eda-11e9-8961-46100fea4675.png)  
사실 KL divergence는 asymmetric하기 때문에 distance metric의 조건을 만족하지 못하는 weak metric이다. 반면 JS divergence는 symmetricity를 만족하며, 따라서 두 비슷한 probabilistic distribution의 분포 차이를 설명할 때는 JS divergence가 더 좋은 metric이라고 할 수 있다.  
  
반면 앞서 언급했듯이 VAE는 MLE problem을 푸는 과정에서 KL divergence를 loss로 활용한다. 즉 GAN은 근본적으로 sampling-based 알고리즘으로써 MLE를 직접적인 objective function으로 활용하지 않으며, 여기서 두 알고리즘의 차이가 발생한다. VAE와 GAN의 차이에 대해 Ian Goodfellow가 직접 설명하신 내용은 다음과 같다. [Link](https://www.quora.com/What-are-the-pros-and-cons-of-Generative-Adversarial-Networks-vs-Variational-Autoencoders)  
  
VAE는 MLE를 Optimize하기 때문에 각 training data points와 그 주변에 대해 반드시 'probability mass'를 할당해야 한다. KL-divergence는 
그 특성상 p의 support에 q의 probability가 0으로 할당될 경우 그 값이 발산해 버리기 때문이다. 이를 링크에서는 "always bleeds probability mass away from the estimated data manifold"라고 표현했다. 반면 GAN은 JS-divergence를 minimize하기 때문에 이 문제에 강하며, 상대적으로 훨씬 sharp한, 즉 더욱 확률적으로 선명하며 blurred되지 않은 이미지를 얻을 가능성이 높다. 특정 Training data point와 거리적으로 크게 멀지는 않지만, 그렇다고 training data와 동일하진 않은 image에 높은 probability mass를 줄 수 있는 것이다. 
  
또한 VAE는 기본적으로 posterior inference를 하기 위한 도구이기 때문에, 복잡한 posterior distribution을 보다 간단한 conjugate variational distribution으로 근사하는 과정이 필수이다. 이 과정에서 취할 수 있는 분포와 parameter가 한정적이기 때문에, information leak이 생기고 한정적으로 image를 표현하게 된다. 반면 이는 VAE의 장점이기도 한데, 특정 분포를 취해 analytical하게 분석할 수 있기 때문에 복잡한 latent distribution을 modeling할 수 있다. 따라서 return 자체보다 underlying latent distribution을 연구, 분석해야 할 경우 GAN보다 VAE가 맞는 방향이라고 할 수 있겠다.
  
  
**1. Practical and Theoretical Limitation of training GAN**  
GAN은 두 network가 경쟁적으로 학습되기 때문에 그 균형점을 (e.g., Nash equilibrium in game theory) 찾기가 쉽지 않다. 
특히 앞서 언급했던 GAN의 theoretical assumption과의 괴리에서 여러 문제가 발생한다.
- Discriminator의 Global bayes optimal
  - 실제 Discriminator는 finite neural network를 사용하기 때문에 sub optimal state를 취하기 쉽다. 이는 
- Discriminator가 위의 optimal state일 때 Generator를 학습시킨다. 
또한 GAN은 이 JS divergence를 minimize하여 unique global optimum에 도달할 수 있는데, 이 때 필요한 가정은 
- G와 D가 enough capacity(in terms of probabilistic distribution)을 가져야 한다.
- Discriminator가 optimal state에 도달할 수 있다.


**2. Theoretical: WGAN and WGAN-GP**  

**3. Practical examples: Tricks and Training**  

**4. Other GANs**  
